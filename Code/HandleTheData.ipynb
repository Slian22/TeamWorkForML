{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from QuickInit import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[ 0.  0. 32. ...  2.  2.  2.]\n",
      " [ 0.  0. 29. ...  0.  0.  0.]\n",
      " [ 0.  0. 31. ...  6. 10. 10.]\n",
      " ...\n",
      " [ 0.  0. 28. ...  0.  0.  0.]\n",
      " [ 0.  0. 23. ...  1.  7.  1.]\n",
      " [ 1.  0. 35. ...  1.  1.  1.]]\n",
      "  (0, 0)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 18)\t1.0\n",
      "  (0, 46)\t1.0\n",
      "  (0, 48)\t1.0\n",
      "  (0, 50)\t1.0\n",
      "  (0, 52)\t1.0\n",
      "  (0, 54)\t1.0\n",
      "  (0, 56)\t1.0\n",
      "  (0, 59)\t1.0\n",
      "  (0, 61)\t1.0\n",
      "  (0, 62)\t1.0\n",
      "  (0, 64)\t1.0\n",
      "  (0, 65)\t1.0\n",
      "  (0, 68)\t1.0\n",
      "  (0, 69)\t1.0\n",
      "  (0, 71)\t1.0\n",
      "  (0, 73)\t1.0\n",
      "  (0, 76)\t1.0\n",
      "  (0, 77)\t1.0\n",
      "  (0, 83)\t1.0\n",
      "  (0, 106)\t1.0\n",
      "  (0, 125)\t1.0\n",
      "  (0, 129)\t1.0\n",
      "  (0, 133)\t1.0\n",
      "  :\t:\n",
      "  (11016, 156163)\t1.0\n",
      "  (11016, 156179)\t1.0\n",
      "  (11016, 156192)\t1.0\n",
      "  (11016, 156204)\t1.0\n",
      "  (11016, 156217)\t1.0\n",
      "  (11016, 156523)\t1.0\n",
      "  (11016, 156592)\t1.0\n",
      "  (11016, 156887)\t1.0\n",
      "  (11016, 157067)\t1.0\n",
      "  (11016, 157353)\t1.0\n",
      "  (11016, 158166)\t1.0\n",
      "  (11016, 164665)\t1.0\n",
      "  (11016, 169837)\t1.0\n",
      "  (11016, 170596)\t1.0\n",
      "  (11016, 170611)\t1.0\n",
      "  (11016, 170625)\t1.0\n",
      "  (11016, 170658)\t1.0\n",
      "  (11016, 170689)\t1.0\n",
      "  (11016, 170713)\t1.0\n",
      "  (11016, 170735)\t1.0\n",
      "  (11016, 170789)\t1.0\n",
      "  (11016, 170838)\t1.0\n",
      "  (11016, 170868)\t1.0\n",
      "  (11016, 170898)\t1.0\n",
      "  (11016, 170976)\t1.0\n",
      "       0    1     2    3    4    5    6    7    8    9    ...  190  191  192  \\\n",
      "0        0  0.0  32.0    0    0    0    0    0    0    1  ...  1.0  1.0  2.0   \n",
      "1        0  0.0  29.0    0    0    0    0    0    0    0  ...  0.0  0.0  0.0   \n",
      "2        0  0.0  31.0    0    0    0    0    0    0    0  ...  2.0  2.0  4.0   \n",
      "3        0  0.0  22.0    0    0    0    0    0    0    0  ...  3.0  3.0  3.0   \n",
      "4        0  0.0  31.0    0    0    0    0    0    0    0  ...  0.0  0.0  0.0   \n",
      "...    ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "11012    0  0.0  29.0    0    0    0    0    0    0    0  ...  0.0  0.0  0.0   \n",
      "11013    1  0.0  25.0    0    0    0    0    0    0    0  ...  3.0  3.0  3.0   \n",
      "11014    0  0.0  28.0    0    0    0    0    0    0    0  ...  0.0  0.0  0.0   \n",
      "11015    0  0.0  23.0    0    0    0    0    0    0    0  ...  1.0  0.0  3.0   \n",
      "11016    1  0.0  35.0    0    0    0    0    0    0    0  ...  1.0  1.0  1.0   \n",
      "\n",
      "       193  194  195  196  197   198   199  \n",
      "0      2.0  2.0  2.0  2.0  2.0   2.0   2.0  \n",
      "1      0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "2      4.0  6.0  6.0  6.0  6.0  10.0  10.0  \n",
      "3      3.0  5.0  5.0  3.0  3.0   7.0   7.0  \n",
      "4      0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "...    ...  ...  ...  ...  ...   ...   ...  \n",
      "11012  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "11013  3.0  5.0  5.0  4.0  4.0   7.0   7.0  \n",
      "11014  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "11015  1.0  5.0  1.0  3.0  1.0   7.0   1.0  \n",
      "11016  1.0  1.0  1.0  1.0  1.0   1.0   1.0  \n",
      "\n",
      "[11017 rows x 200 columns]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#One Hot Encode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "Sample_data_Pandas=FillNaN_PD()\n",
    "Sample_data_Numpy=FillNaN_NP()\n",
    "enc_data=OneHotEncoder()\n",
    "print(Sample_data_Numpy)\n",
    "ans=enc_data.fit_transform(Sample_data_Numpy)\n",
    "print(ans)\n",
    "print(Sample_data_Pandas)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0.         0.         0.54237288 ... 0.05714286 0.01104972 0.01515152]\n",
      " [0.         0.         0.49152542 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.52542373 ... 0.17142857 0.05524862 0.07575758]\n",
      " ...\n",
      " [0.         0.         0.47457627 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.38983051 ... 0.02857143 0.03867403 0.00757576]\n",
      " [1.         0.         0.59322034 ... 0.02857143 0.00552486 0.00757576]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler=scaler.fit(Sample_data_Pandas)\n",
    "result=scaler.transform(Sample_data_Pandas)\n",
    "print(result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[[ 0.  0. 32. ...  2.  2.  2.]\n",
      " [ 0.  0. 29. ...  0.  0.  0.]\n",
      " [ 0.  0. 31. ...  6. 10. 10.]\n",
      " ...\n",
      " [ 0.  0. 28. ...  0.  0.  0.]\n",
      " [ 0.  0. 23. ...  1.  7.  1.]\n",
      " [ 1.  0. 35. ...  1.  1.  1.]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#StandarLize The Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "result_=scaler.inverse_transform(result)\n",
    "scaler_2=StandardScaler()\n",
    "scaler_2.fit(Sample_data_Pandas)\n",
    "print(scaler_2)\n",
    "x_std=scaler_2.transform(result_)\n",
    "print(result_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}